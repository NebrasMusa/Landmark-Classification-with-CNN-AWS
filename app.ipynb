{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for Landmark Classification\n",
    "\n",
    "### Install Prerequisites\n",
    "\n",
    "To run the app in the notebook environment, you must first install the required packages by executing the two cells below. **Make sure to restart the kernel after running each cell.**\n",
    "\n",
    "> Note: Restarting the kernel ensures that all installed dependencies are properly loaded into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please restart the notebook kernel after running this cell.\n",
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please restart the notebook kernel after running this cell as well.\n",
    "#!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple App\n",
    "\n",
    "In this notebook we build a very simple app that uses our exported model.\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Note how we are not importing anything from our source code (we do not use any module from the ``src`` directory). This is because the exported model, differently from the model weights, is a standalone serialization of our model and therefore it does not need anything else. You can ship that file to anybody, and as long as they can import ``torch``, they will be able to use your model. This is very important for releasing pytorch models to production.\n",
    "\n",
    "### Test Your App\n",
    "Go to a search engine for images (like Google Images) and search for images of some of the landmarks, like the Eiffel Tower, the Golden Gate Bridge, Machu Picchu and so on. Save a few examples locally, then upload them to your app to see how your model behaves!\n",
    "\n",
    "The app will show the top 5 classes that the model think are most relevant for the picture you have uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import VBox, Button, FileUpload, Output, Label, IntSlider\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Check if model file exists\n",
    "model_path = \"checkpoints/transfer_exported.pt\"\n",
    "if os.path.exists(model_path):\n",
    "    try:\n",
    "        learn_inf = torch.jit.load(model_path)\n",
    "        print(\"Model loaded successfully\")\n",
    "        \n",
    "        # Try to get class names from the model\n",
    "        try:\n",
    "            class_names = learn_inf.get_class_names()\n",
    "            print(f\"Class names loaded from model: {len(class_names)} classes\")\n",
    "        except:\n",
    "            # If model doesn't have class names, try to load from JSON or data loaders\n",
    "            class_names_path = \"checkpoints/class_names.json\"\n",
    "            if os.path.exists(class_names_path):\n",
    "                with open(class_names_path, 'r') as f:\n",
    "                    class_names = json.load(f)\n",
    "                print(f\"Class names loaded from JSON: {len(class_names)} classes\")\n",
    "            else:\n",
    "                # Fallback: try to get from data loaders\n",
    "                try:\n",
    "                    from src.data import get_data_loaders\n",
    "                    data_loaders = get_data_loaders(batch_size=32)\n",
    "                    class_names = data_loaders[\"train\"].dataset.classes\n",
    "                    print(f\"Class names loaded from data: {len(class_names)} classes\")\n",
    "                except:\n",
    "                    # Last resort: create dummy class names\n",
    "                    class_names = [f\"Class_{i}\" for i in range(50)]\n",
    "                    print(f\"Using dummy class names: {len(class_names)} classes\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        learn_inf = None\n",
    "        class_names = []\n",
    "else:\n",
    "    print(f\"Model file not found at {model_path}\")\n",
    "    learn_inf = None\n",
    "    class_names = []\n",
    "\n",
    "def on_click_classify(change):\n",
    "    if learn_inf is None:\n",
    "        print(\"Model not loaded. Cannot classify.\")\n",
    "        return\n",
    "        \n",
    "    if len(btn_upload.data) == 0:\n",
    "        return  # No file uploaded yet\n",
    "\n",
    "    # Load image that has been uploaded\n",
    "    try:\n",
    "        fn = io.BytesIO(btn_upload.data[-1])\n",
    "        img = Image.open(fn).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return\n",
    "\n",
    "    # Let's clear the previous output (if any)\n",
    "    out_pl.clear_output()\n",
    "\n",
    "    # Display the image\n",
    "    with out_pl:\n",
    "        ratio = img.size[0] / img.size[1]\n",
    "        c = img.copy()\n",
    "        c.thumbnail([ratio * 200, 200])\n",
    "        display(c)\n",
    "\n",
    "    # Transform the image\n",
    "    try:\n",
    "        # Use the same preprocessing as in your Predictor class\n",
    "        transform = T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.4638, 0.4725, 0.4687], std=[0.2699, 0.2706, 0.3018])  # Use your dataset stats\n",
    "        ])\n",
    "\n",
    "        timg = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Move model and input to CPU or GPU\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        timg = timg.to(device)\n",
    "        learn_inf.to(device)\n",
    "\n",
    "        # Call the model\n",
    "        with torch.no_grad():\n",
    "            softmax = learn_inf(timg).cpu().numpy().squeeze()\n",
    "\n",
    "        # Get class indices sorted by probability (highest first)\n",
    "        idxs = np.argsort(softmax)[::-1]\n",
    "\n",
    "        # Loop over the top 5 predictions\n",
    "        for i in range(5):\n",
    "            p = softmax[idxs[i]]\n",
    "            if i < len(class_names):\n",
    "                landmark_name = class_names[idxs[i]]\n",
    "                labels[i].value = f\"{landmark_name} (prob: {p:.4f})\"\n",
    "            else:\n",
    "                labels[i].value = f\"Class {idxs[i]} (prob: {p:.4f})\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during classification: {e}\")\n",
    "        for label in labels:\n",
    "            label.value = \"Error occurred\"\n",
    "\n",
    "# Widgets setup\n",
    "btn_upload = FileUpload(accept='image/*', multiple=False)\n",
    "btn_run = Button(description=\"Classify\")\n",
    "btn_run.on_click(on_click_classify)\n",
    "out_pl = Output()\n",
    "out_pl.clear_output()\n",
    "\n",
    "labels = [Label() for _ in range(5)]\n",
    "\n",
    "wgs = [Label(\"Please upload a picture of a food item\"), btn_upload, btn_run, out_pl]\n",
    "wgs.extend(labels)\n",
    "\n",
    "# Display the interactive app\n",
    "VBox(wgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Standalone App or Web App\n",
    "\n",
    "You can run this notebook as a standalone app on your computer by following these steps:\n",
    "\n",
    "1. Download this notebook in a directory on your machine\n",
    "2. Download the model export (for example, ``checkpoints/transfer_exported.pt``) in a subdirectory called ``checkpoints`` within the directory where you save the app.ipynb notebook\n",
    "3. Install voila if you don't have it already (``pip install voila``)\n",
    "4. Run your app: ``voila app.ipynb --show_tracebacks=True``\n",
    "5. Customize your notebook to make your app prettier and rerun voila\n",
    "\n",
    "You can also deploy this app as a website using Binder: https://voila.readthedocs.io/en/stable/deploy.html#deployment-on-binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Your Submission Archive\n",
    "\n",
    "Now that you are done with your project, please run the following cell. It will generate a file containing all the code you have written, as well as the notebooks. Please submit that file to complete your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/create_submit_pkg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
